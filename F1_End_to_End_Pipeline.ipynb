{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# End-to-End F1 Race Position Prediction Pipeline\n",
                "\n",
                "## Introduction\n",
                "\n",
                "This notebook presents a comprehensive workflow for predicting Formula 1 race outcomes using Deep Learning. By analyzing driver performance data from Practice and Qualifying sessions, we aim to forecast the final finishing position of each driver before the race begins.\n",
                "\n",
                "The project demonstrates a complete machine learning lifecycle, from raw data ingestion to model deployment.\n",
                "\n",
                "### Project Architecture\n",
                "\n",
                "The pipeline is structured into five distinct stages:\n",
                "\n",
                "1.  **Dataset Creation:** We start by aggregating raw session files (lap times, weather conditions, tire stints) from the OpenF1 API into a unified master dataset.\n",
                "2.  **Feature Engineering:** Raw data is transformed into 22 meaningful performance metrics, such as practice pace, tire degradation proxies, and qualifying improvements.\n",
                "3.  **Exploratory Data Analysis (EDA):** We visualize correlations and distributions to understand the factors that drive race results.\n",
                "4.  **Model Development:** We design and train a Deep Feedforward Neural Network (DNN) using PyTorch, optimized for regression tasks.\n",
                "5.  **Evaluation & Testing:** The model's performance is rigorously tested on unseen data to quantify its predictive accuracy in real-world scenarios."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup\n",
                "\n",
                "We begin by initializing our development environment. We rely on a robust stack of data science libraries:\n",
                "\n",
                "*   **PyTorch:** The core deep learning framework used for building and training our neural network.\n",
                "*   **Pandas & NumPy:** Essential for high-performance data manipulation and numerical operations.\n",
                "*   **Seaborn & Matplotlib:** Used to create insightful visualizations that help us interpret our data and model results.\n",
                "*   **Scikit-Learn:** Provides utility functions for data splitting and feature scaling."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "import ast\n",
                "import time\n",
                "from glob import glob\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# Configure plotting aesthetics for clear, professional visuals\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.size'] = 12\n",
                "\n",
                "print(\"Libraries imported successfully. Environment is ready.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Master Dataset Construction\n",
                "\n",
                "The foundation of any machine learning model is high-quality data. In this step, we consolidate fragmented session files into a single, coherent dataset.\n",
                "\n",
                "The `build_master_dataset` function is designed to iterate through our repository of raw session files. For each race weekend, it links Practice, Qualifying, and Race sessions, ensuring that every driver's weekend journey is captured in a single record.\n",
                "\n",
                "> **Note:** This block assumes the presence of raw data in the `all_session_data/` directory. If the `master_dataset.csv` already exists, this step can be skipped."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration Paths\n",
                "DATA_DIR = \"all_session_data\"\n",
                "SESSIONS_DIR = \"sessions\"\n",
                "OUTPUT_FILE = \"master_dataset.csv\"\n",
                "\n",
                "def build_master_dataset():\n",
                "    if not os.path.exists(SESSIONS_DIR):\n",
                "        print(f\"Directory {SESSIONS_DIR} not found. Skipping dataset build.\")\n",
                "        return\n",
                "        \n",
                "    print(\"Initiating Master Dataset Construction...\")\n",
                "    # This section would contain the logic to parse CSVs, match session keys,\n",
                "    # and aggregate lap times. For this notebook, we assume the builder script\n",
                "    # has already been run or the logic is imported.\n",
                "    print(\"Dataset builder logic placeholder.\")\n",
                "    print(\"Please run 'python master_dataset_builder.py' to rebuild from raw files.\")\n",
                "\n",
                "# build_master_dataset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Engineering\n",
                "\n",
                "Raw lap times alone are insufficient for predictive modeling. We need to extract signals that indicate a driver's true potential.\n",
                "\n",
                "In this phase, we transform the raw data into 22 distinct features. Key engineered features include:\n",
                "\n",
                "*   **Practice Pace (`practice_best_lap`):** The single fastest lap recorded during practice, serving as a baseline for raw speed.\n",
                "*   **Qualifying Improvement (`practice_vs_quali_improvement`):** Measures a driver's ability to find extra performance under pressure. A large improvement suggests the car has hidden potential.\n",
                "*   **Tire Usage (`practice_total_tire_laps`):** Indicates how much data the team gathered on tire degradation, which correlates with race strategy execution.\n",
                "*   **Grid Position (`grid_position`):** Historically the most significant predictor, but our model aims to look beyond just where they start."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_feature_engineering():\n",
                "    if not os.path.exists('master_dataset.csv'):\n",
                "        print(\"Error: master_dataset.csv not found. Please ensure it exists.\")\n",
                "        return\n",
                "\n",
                "    print(\"Starting Feature Engineering process...\")\n",
                "    df = pd.read_csv('master_dataset.csv')\n",
                "    \n",
                "    # Separate data by session type for targeted aggregation\n",
                "    practice = df[df['session_type'] == 'Practice'].copy()\n",
                "    qualifying = df[df['session_type'] == 'Qualifying'].copy()\n",
                "    race = df[df['session_type'] == 'Race'].copy()\n",
                "\n",
                "    # 1. Aggregate Practice Data\n",
                "    # We combine data from FP1, FP2, and FP3 to get a holistic view of practice performance\n",
                "    practice_agg = practice.groupby(['meeting_key', 'driver_name']).agg({\n",
                "        'best_lap_time': ['min', 'mean'],\n",
                "        'total_laps': 'sum',\n",
                "        'best_sector_1': 'min', 'best_sector_2': 'min', 'best_sector_3': 'min',\n",
                "        'avg_i1_speed': 'mean', 'avg_i2_speed': 'mean', 'avg_st_speed': 'mean',\n",
                "        'purple_sectors_count': 'sum', 'green_sectors_count': 'sum',\n",
                "        'total_soft_laps': 'sum', 'total_medium_laps': 'sum', 'total_hard_laps': 'sum',\n",
                "    }).reset_index()\n",
                "    \n",
                "    # Flatten hierarchical column names for easier access\n",
                "    practice_agg.columns = ['_'.join(col).strip('_') if col[1] else col[0] for col in practice_agg.columns.values]\n",
                "    practice_agg = practice_agg.rename(columns={\n",
                "        'best_lap_time_min': 'practice_best_lap',\n",
                "        'best_lap_time_mean': 'practice_avg_best_lap',\n",
                "        'total_laps_sum': 'practice_total_laps',\n",
                "        'best_sector_1_min': 'practice_best_s1',\n",
                "        'best_sector_2_min': 'practice_best_s2',\n",
                "        'best_sector_3_min': 'practice_best_s3',\n",
                "        'avg_i1_speed_mean': 'practice_avg_i1_speed',\n",
                "        'avg_i2_speed_mean': 'practice_avg_i2_speed',\n",
                "        'avg_st_speed_mean': 'practice_avg_st_speed',\n",
                "        'purple_sectors_count_sum': 'practice_purple_sectors',\n",
                "        'green_sectors_count_sum': 'practice_green_sectors',\n",
                "        'total_soft_laps_sum': 'practice_soft_laps',\n",
                "        'total_medium_laps_sum': 'practice_medium_laps',\n",
                "        'total_hard_laps_sum': 'practice_hard_laps',\n",
                "    })\n",
                "\n",
                "    # 2. Prepare Qualifying Data\n",
                "    # We extract the absolute best lap time achieved in qualifying\n",
                "    quali_agg = qualifying.groupby(['meeting_key', 'driver_name']).agg({\n",
                "        'best_lap_time': 'min',\n",
                "        'best_sector_1': 'min', 'best_sector_2': 'min', 'best_sector_3': 'min',\n",
                "    }).reset_index().rename(columns={\n",
                "        'best_lap_time': 'quali_best_lap',\n",
                "        'best_sector_1': 'quali_best_s1',\n",
                "        'best_sector_2': 'quali_best_s2',\n",
                "        'best_sector_3': 'quali_best_s3',\n",
                "    })\n",
                "\n",
                "    # 3. Prepare Race Results (Target Variable)\n",
                "    # This contains the ground truth we want to predict\n",
                "    race_agg = race.groupby(['meeting_key', 'driver_name']).agg({\n",
                "        'starting_position': 'first',\n",
                "        'finishing_position': 'first',\n",
                "        'points': 'first',\n",
                "    }).reset_index().rename(columns={'starting_position': 'grid_position'})\n",
                "\n",
                "    # 4. Merge Datasets\n",
                "    # We use inner joins to ensure we only keep records where we have data for all three session types\n",
                "    dataset = practice_agg.merge(quali_agg, on=['meeting_key', 'driver_name'], how='inner')\n",
                "    dataset = dataset.merge(race_agg, on=['meeting_key', 'driver_name'], how='inner')\n",
                "\n",
                "    # 5. Data Cleaning & Derived Features\n",
                "    dataset = dataset.dropna(subset=['practice_best_lap', 'grid_position', 'finishing_position'])\n",
                "    dataset['practice_total_sectors'] = dataset['practice_best_s1'] + dataset['practice_best_s2'] + dataset['practice_best_s3']\n",
                "    dataset['practice_vs_quali_improvement'] = dataset['practice_best_lap'] - dataset['quali_best_lap']\n",
                "    dataset['practice_total_tire_laps'] = dataset['practice_soft_laps'] + dataset['practice_medium_laps'] + dataset['practice_hard_laps']\n",
                "\n",
                "    dataset.to_csv('training_dataset.csv', index=False)\n",
                "    print(f\"Feature Engineering Complete. Training dataset saved with {len(dataset)} examples.\")\n",
                "    return dataset\n",
                "\n",
                "df = run_feature_engineering()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Exploratory Data Analysis (EDA)\n",
                "\n",
                "Before diving into model training, it is crucial to understand the statistical properties of our data. We will use visualization to uncover patterns and potential biases.\n",
                "\n",
                "We will examine:\n",
                "1.  **Distributions:** Are the finishing positions evenly distributed, or are there anomalies?\n",
                "2.  **Correlations:** Which features have the strongest relationship with the finishing position? This helps us verify our feature engineering assumptions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if os.path.exists('training_dataset.csv'):\n",
                "    df = pd.read_csv('training_dataset.csv')\n",
                "    \n",
                "    # 1. Position Distributions\n",
                "    plt.figure(figsize=(14, 5))\n",
                "    \n",
                "    plt.subplot(1, 2, 1)\n",
                "    sns.histplot(df['grid_position'], bins=20, kde=False, color='#3498db', edgecolor='black')\n",
                "    plt.title('Distribution of Starting Grid Positions')\n",
                "    plt.xlabel('Grid Position')\n",
                "    plt.ylabel('Frequency')\n",
                "    \n",
                "    plt.subplot(1, 2, 2)\n",
                "    sns.histplot(df['finishing_position'], bins=20, kde=False, color='#e74c3c', edgecolor='black')\n",
                "    plt.title('Distribution of Finishing Positions')\n",
                "    plt.xlabel('Finishing Position')\n",
                "    plt.ylabel('Frequency')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # 2. Correlation Heatmap\n",
                "    # We select a subset of key features to keep the heatmap readable\n",
                "    plt.figure(figsize=(12, 10))\n",
                "    cols_to_plot = ['finishing_position', 'grid_position', 'quali_best_lap', \n",
                "                    'practice_best_lap', 'practice_avg_st_speed', 'practice_total_laps']\n",
                "    \n",
                "    corr_matrix = df[cols_to_plot].corr()\n",
                "    \n",
                "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, square=True)\n",
                "    plt.title('Feature Correlation Matrix')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Neural Network Architecture Design\n",
                "\n",
                "We have chosen a **Multi-Layer Perceptron (MLP)** for this regression task. The architecture is designed to capture non-linear relationships between the input features and the target variable.\n",
                "\n",
                "**Key Architectural Decisions:**\n",
                "\n",
                "*   **Tapering Layer Sizes (128 -> 64 -> 32):** This structure forces the network to learn increasingly abstract and compressed representations of the input data.\n",
                "*   **Batch Normalization:** Applied after each linear layer to stabilize learning and allow for higher learning rates.\n",
                "*   **Dropout:** We use dropout layers (30% and 20%) to prevent overfitting. This forces the network to learn robust features rather than memorizing specific training examples.\n",
                "*   **ReLU Activation:** Used to introduce non-linearity, allowing the model to learn complex patterns.\n",
                "*   **Single Output Neuron:** Since this is a regression problem (predicting a position from 1 to 20), we use a single output neuron with no activation function, allowing it to predict any continuous value."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class F1DeepPredictor(nn.Module):\n",
                "    def __init__(self, input_features=22):\n",
                "        super(F1DeepPredictor, self).__init__()\n",
                "        \n",
                "        # Layer 1: Input -> 128 Neurons\n",
                "        # High dimensionality in the first layer helps capture complex interactions\n",
                "        self.fc1 = nn.Linear(input_features, 128)\n",
                "        self.bn1 = nn.BatchNorm1d(128)\n",
                "        self.dropout1 = nn.Dropout(0.3)\n",
                "        \n",
                "        # Layer 2: 128 -> 64 Neurons\n",
                "        self.fc2 = nn.Linear(128, 64)\n",
                "        self.bn2 = nn.BatchNorm1d(64)\n",
                "        self.dropout2 = nn.Dropout(0.3)\n",
                "        \n",
                "        # Layer 3: 64 -> 32 Neurons\n",
                "        self.fc3 = nn.Linear(64, 32)\n",
                "        self.bn3 = nn.BatchNorm1d(32)\n",
                "        self.dropout3 = nn.Dropout(0.2)\n",
                "        \n",
                "        # Output Layer: 32 -> 1 Neuron\n",
                "        # Outputs a continuous value representing the predicted position\n",
                "        self.fc4 = nn.Linear(32, 1)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # Forward pass with ReLU activation and Dropout\n",
                "        x = F.relu(self.bn1(self.fc1(x)))\n",
                "        x = self.dropout1(x)\n",
                "        \n",
                "        x = F.relu(self.bn2(self.fc2(x)))\n",
                "        x = self.dropout2(x)\n",
                "        \n",
                "        x = F.relu(self.bn3(self.fc3(x)))\n",
                "        x = self.dropout3(x)\n",
                "        \n",
                "        x = self.fc4(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Model Training Loop\n",
                "\n",
                "With our architecture defined, we proceed to train the model. The training process involves iterating through the dataset for **100 epochs**.\n",
                "\n",
                "**Training Configuration:**\n",
                "*   **Optimizer:** Adam (Adaptive Moment Estimation) is used for its efficiency and ability to handle sparse gradients.\n",
                "*   **Loss Function:** Mean Squared Error (MSE) is chosen as it penalizes larger prediction errors more heavily, encouraging the model to be precise.\n",
                "*   **Data Splitting:** We strictly separate our data into Training, Validation, and Test sets to ensure unbiased evaluation.\n",
                "\n",
                "We also implement real-time monitoring of Training Loss and Validation MAE to detect overfitting early."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_f1_model():\n",
                "    if not os.path.exists('training_dataset.csv'):\n",
                "        return\n",
                "\n",
                "    print(\"Preparing data for training...\")\n",
                "    df = pd.read_csv('training_dataset.csv')\n",
                "    feature_cols = [col for col in df.columns if col not in ['meeting_key', 'driver_name', 'finishing_position', 'points']]\n",
                "    \n",
                "    X = df[feature_cols].values\n",
                "    y = df['finishing_position'].values.astype(float)\n",
                "\n",
                "    # Preprocessing: Handle Missing Values & Normalize\n",
                "    nan_mask = np.isnan(X)\n",
                "    if nan_mask.any():\n",
                "        col_means = np.nanmean(X, axis=0)\n",
                "        for i in range(X.shape[1]):\n",
                "            X[nan_mask[:, i], i] = col_means[i]\n",
                "\n",
                "    scaler = StandardScaler()\n",
                "    X_scaled = scaler.fit_transform(X)\n",
                "    # Clip outliers to prevent gradient instability\n",
                "    X_scaled = np.clip(X_scaled, -5, 5)\n",
                "\n",
                "    # Split Data: Train (70%), Val (10%), Test (20%)\n",
                "    X_temp, X_test, y_temp, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
                "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=42)\n",
                "\n",
                "    # Create PyTorch DataLoaders\n",
                "    train_loader = DataLoader(TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train)), batch_size=16, shuffle=True)\n",
                "    val_loader = DataLoader(TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val)), batch_size=16, shuffle=False)\n",
                "    test_loader = DataLoader(TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test)), batch_size=16, shuffle=False)\n",
                "\n",
                "    # Initialize Model components\n",
                "    model = F1DeepPredictor(input_features=len(feature_cols))\n",
                "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
                "    criterion = nn.MSELoss()\n",
                "\n",
                "    # Training Loop\n",
                "    history = {'train_loss': [], 'val_loss': [], 'val_mae': []}\n",
                "    num_epochs = 100\n",
                "    \n",
                "    print(f\"Starting training for {num_epochs} epochs...\")\n",
                "    \n",
                "    for epoch in range(num_epochs):\n",
                "        model.train()\n",
                "        train_loss = 0.0\n",
                "        for batch_X, batch_y in train_loader:\n",
                "            outputs = model(batch_X).squeeze()\n",
                "            loss = criterion(outputs, batch_y)\n",
                "            optimizer.zero_grad()\n",
                "            loss.backward()\n",
                "            # Gradient clipping prevents exploding gradients\n",
                "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "            optimizer.step()\n",
                "            train_loss += loss.item()\n",
                "        \n",
                "        # Validation Phase\n",
                "        model.eval()\n",
                "        val_loss = 0.0\n",
                "        val_mae = 0.0\n",
                "        with torch.no_grad():\n",
                "            for batch_X, batch_y in val_loader:\n",
                "                outputs = model(batch_X).squeeze()\n",
                "                loss = criterion(outputs, batch_y)\n",
                "                val_loss += loss.item()\n",
                "                val_mae += torch.abs(outputs - batch_y).sum().item()\n",
                "        \n",
                "        # Store metrics for visualization\n",
                "        history['train_loss'].append(train_loss / len(train_loader))\n",
                "        history['val_loss'].append(val_loss / len(val_loader))\n",
                "        history['val_mae'].append(val_mae / len(val_loader.dataset))\n",
                "\n",
                "    # Visualization: Training Curves\n",
                "    plt.figure(figsize=(14, 5))\n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
                "    plt.plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
                "    plt.title('Learning Curve: Loss over Epochs')\n",
                "    plt.xlabel('Epoch')\n",
                "    plt.ylabel('MSE Loss')\n",
                "    plt.legend()\n",
                "    \n",
                "    plt.subplot(1, 2, 2)\n",
                "    plt.plot(history['val_mae'], color='green', label='Validation MAE', linewidth=2)\n",
                "    plt.title('Validation Mean Absolute Error')\n",
                "    plt.xlabel('Epoch')\n",
                "    plt.ylabel('MAE (Positions)')\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "    \n",
                "    # Save the trained model artifact\n",
                "    torch.save({\n",
                "        'model_state': model.state_dict(),\n",
                "        'scaler': scaler,\n",
                "        'features': feature_cols,\n",
                "    }, 'f1_model.pth')\n",
                "    \n",
                "    return model, scaler, feature_cols, X_test, y_test\n",
                "\n",
                "model, scaler, feature_cols, X_test, y_test = train_f1_model()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluation & Results Analysis\n",
                "\n",
                "The final step is to rigorously evaluate our model on the Test Set—data that the model has never seen during training.\n",
                "\n",
                "We use two primary visualizations to assess performance:\n",
                "1.  **Predicted vs. Actual Scatter Plot:** Ideally, all points should lie on the red diagonal line. Deviations from this line represent prediction errors.\n",
                "2.  **Error Distribution Histogram:** This shows us the spread of our errors. A narrow, tall peak centered at zero indicates a highly accurate model.\n",
                "\n",
                "We also calculate key metrics like **Mean Absolute Error (MAE)** and **Accuracy within ±N positions** to give us concrete performance numbers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions on the test set\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    X_test_tensor = torch.FloatTensor(X_test)\n",
                "    predictions_raw = model(X_test_tensor).squeeze().numpy()\n",
                "    # Clip predictions to valid range [1, 20] and round to nearest integer\n",
                "    predictions = np.clip(np.round(predictions_raw), 1, 20)\n",
                "\n",
                "# 1. Visualization: Predicted vs Actual\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.scatter(y_test, predictions, alpha=0.6, color='#8e44ad', edgecolors='w', s=80)\n",
                "plt.plot([1, 20], [1, 20], 'r--', linewidth=2, label='Perfect Prediction')\n",
                "plt.xlabel('Actual Finishing Position')\n",
                "plt.ylabel('Predicted Finishing Position')\n",
                "plt.title('Model Accuracy: Predicted vs Actual Results')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "# 2. Visualization: Error Distribution\n",
                "errors = predictions - y_test\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.histplot(errors, bins=15, kde=True, color='#16a085')\n",
                "plt.title('Distribution of Prediction Errors')\n",
                "plt.xlabel('Error (Predicted - Actual)')\n",
                "plt.ylabel('Frequency')\n",
                "plt.axvline(0, color='red', linestyle='--', label='Zero Error')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Calculate and Print Final Metrics\n",
                "mae = np.abs(errors).mean()\n",
                "within_1 = (np.abs(errors) <= 1).sum() / len(errors) * 100\n",
                "within_3 = (np.abs(errors) <= 3).sum() / len(errors) * 100\n",
                "\n",
                "print(f\"Final Model Evaluation Results:\")\n",
                "print(f\"   Mean Absolute Error: {mae:.2f} positions\")\n",
                "print(f\"   Accuracy (within ±1 position): {within_1:.1f}%\")\n",
                "print(f\"   Accuracy (within ±3 positions): {within_3:.1f}%\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
